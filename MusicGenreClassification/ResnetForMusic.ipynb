{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a16d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 513, 245)\n",
      "[[0.85420213 0.85244615 0.78359503 ... 0.84777877 0.84317175 0.84454527]\n",
      " [0.98867201 0.93291589 0.93872781 ... 0.9161695  0.92045293 0.9191017 ]\n",
      " [0.94581499 0.92631355 0.93578885 ... 0.95866542 0.955151   0.9596596 ]\n",
      " ...\n",
      " [0.35289731 0.41147769 0.40065432 ... 0.39905583 0.38606621 0.36785466]\n",
      " [0.37948273 0.41369067 0.37228786 ... 0.39083571 0.37346232 0.39343748]\n",
      " [0.40716169 0.31949731 0.31204434 ... 0.35099331 0.29015256 0.39404925]]\n"
     ]
    }
   ],
   "source": [
    "#currently using the small extracted datafile with 24 testdata; \n",
    "# keep getting error on loss=criterion(outputs,y)---- target out of bound\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device=\"cpu\"\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n",
    "        super(Block, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        if self.num_layers > 34:\n",
    "            self.expansion = 4\n",
    "        else:\n",
    "            self.expansion = 1\n",
    "        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        if self.num_layers > 34:\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        else:\n",
    "            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n",
    "            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.num_layers > 34:\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_layers, block, image_channels, num_classes):\n",
    "        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n",
    "                                                     f'to be 18, 34, 50, 101, or 152 '\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers < 50:\n",
    "            self.expansion = 1\n",
    "        else:\n",
    "            self.expansion = 4\n",
    "        if num_layers == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "        elif num_layers == 34 or num_layers == 50:\n",
    "            layers = [3, 4, 6, 3]\n",
    "        elif num_layers == 101:\n",
    "            layers = [3, 4, 23, 3]\n",
    "        else:\n",
    "            layers = [3, 8, 36, 3]\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNetLayers\n",
    "        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * self.expansion, num_classes)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        x = self.conv1(x)\n",
    "        print(\"forward after conv1 \"+str(x.size()))\n",
    "        x = self.bn1(x)\n",
    "        print(\"forward after bn1 \"+str(x.size()))\n",
    "        x = self.relu(x)\n",
    "        print(\"forward after relu \"+str(x.size()))\n",
    "        x = self.maxpool(x)\n",
    "        print(\"forward after maxpool \"+str(x.size()))\n",
    "        x = self.layer1(x)\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        x = self.layer2(x)\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        x = self.layer3(x)\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        x = self.layer4(x)\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        x = self.avgpool(x)\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        x = self.fc(x)\n",
    "        print(\"forward \"+str(x.size()))\n",
    "        return x\n",
    "\n",
    "    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        layers = []\n",
    "\n",
    "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n",
    "                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n",
    "        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "        self.in_channels = intermediate_channels * self.expansion # 256\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def ResNet18(img_channels=3, num_classes=1000):\n",
    "    return ResNet(18, Block, img_channels, num_classes)\n",
    "\n",
    "\n",
    "def ResNet34(img_channels=3, num_classes=1000):\n",
    "    return ResNet(34, Block, img_channels, num_classes)\n",
    "\n",
    "\n",
    "def ResNet50(img_channels=3, num_classes=1000):\n",
    "    return ResNet(50, Block, img_channels, num_classes)\n",
    "\n",
    "\n",
    "def ResNet101(img_channels=3, num_classes=1000):\n",
    "    return ResNet(101, Block, img_channels, num_classes)\n",
    "\n",
    "\n",
    "def ResNet152(img_channels=3, num_classes=1000):\n",
    "    return ResNet(152, Block, img_channels, num_classes)\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "        def __init__(self,X,Y):\n",
    "            self.X=X\n",
    "            self.Y=Y\n",
    "            self.N=self.X.shape[0]\n",
    "            self.K=self.X.shape[1]\n",
    "        def __len__(self):\n",
    "            return(self.N)\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X[idx],self.Y[idx]\n",
    "\n",
    "Xtrain=np.load(\"MusicTrainingImagesReshaped2.npy\")\n",
    "print(Xtrain.shape)\n",
    "print(Xtrain[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8efd58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read from disk\n",
      "created training & testing data\n",
      "<class 'numpy.ndarray'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "Ytrain=np.load(\"MusicTrainingLabels2.npy\")\n",
    "\n",
    "Xtest=np.load(\"MusicTestingImagesReshaped2.npy\")\n",
    "Ytest=np.load(\"MusicTestingLabels2.npy\")\n",
    "ntest=Xtest.shape[0]\n",
    "print(\"data read from disk\")\n",
    "\n",
    "TrainingData=MyDataSet(Xtrain,Ytrain)\n",
    "TestingData=MyDataSet(Xtest,Ytest)\n",
    "\n",
    "print(\"created training & testing data\")\n",
    "print(type(Ytrain))\n",
    "print(Ytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc84ec2-cdc3-4290-b8e2-6e7d78b13ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created data loader\n",
      "created model\n",
      "epoch = 0\n",
      "torch.Size([3, 1, 513, 245])\n",
      "i = 0\n",
      "tensor([3, 2, 0]) 3 y\n",
      "torch.Size([3, 1, 513, 245]) x size\n",
      "forward torch.Size([3, 1, 513, 245])\n",
      "forward after conv1 torch.Size([3, 64, 257, 123])\n",
      "forward after bn1 torch.Size([3, 64, 257, 123])\n",
      "forward after relu torch.Size([3, 64, 257, 123])\n",
      "forward after maxpool torch.Size([3, 64, 129, 62])\n",
      "forward torch.Size([3, 64, 129, 62])\n",
      "forward torch.Size([3, 128, 65, 31])\n",
      "forward torch.Size([3, 256, 33, 16])\n",
      "forward torch.Size([3, 512, 17, 8])\n",
      "forward torch.Size([3, 512, 1, 1])\n",
      "forward torch.Size([3, 512])\n",
      "forward torch.Size([3, 2])\n",
      "3 output size\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 3 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m outputs\u001b[38;5;241m=\u001b[39mmodel(x)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outputs), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 51\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# compute gradients\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3025\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 3 is out of bounds."
     ]
    }
   ],
   "source": [
    "DataLoader_train=torch.utils.data.DataLoader(\n",
    "    dataset=TrainingData,\n",
    "    batch_size=3,\n",
    "    shuffle=True)\n",
    "\n",
    "print(\"created data loader\")\n",
    "\n",
    "learning_rate = .01\n",
    "num_epochs=1\n",
    "\n",
    "model = ResNet18(img_channels=1, num_classes=2)\n",
    "\n",
    "print(\"created model\")\n",
    "\n",
    "\n",
    "#\n",
    "# move the model to the device\n",
    "#\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#\n",
    "# Adam is an optimizer that maintains a different learning \n",
    "# rate for every weight/parameter in the network - so the learning rate \n",
    "# is a relative one\n",
    "#\n",
    "# See the gentle introduction:\n",
    "#        e.g. https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "#\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch = \"+str(epoch))\n",
    "    #\n",
    "    # for each epoch the data loader loads the data one batch at a time\n",
    "    #\n",
    "    for i,(x,y) in enumerate(DataLoader_train):\n",
    "        if i>1:\n",
    "            break\n",
    "        print(x.shape)\n",
    "        print(\"i = \"+str(i))\n",
    "        x=x.float()\n",
    "        x=x.to(device)\n",
    "        y=y.to(device,dtype=torch.long)\n",
    "        print(y,len(y),'y')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(x.size(),'x size')\n",
    "        outputs=model(x)\n",
    "        print(len(outputs), 'output size')\n",
    "\n",
    "        loss=criterion(outputs,y)\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        loss.backward() # compute gradients\n",
    "\n",
    "        # move in direction of minus the gradient by a learning_rate amount \n",
    "        # here because we are using Adam, step is more complicated than -epsilon*Gradient\n",
    "        optimizer.step() \n",
    "        #print(\"epoch = {0:5d} i = {1:5d} loss = {2:8.5f}\".format(epoch,i,loss_value))\n",
    "    print(\"epoch = {0:5d} loss = {1:8.5f}\".format(epoch,loss_value))\n",
    "#\n",
    "nclasses=2\n",
    "Confusion=np.zeros(shape=(nclasses,nclasses),dtype=int)\n",
    "xtest=torch.tensor(Xtest).float().to(device)\n",
    "ypred=model(xtest)\n",
    "ypred=ypred.cpu().detach().numpy()\n",
    "ypred=np.apply_along_axis(np.argmax,1,ypred)\n",
    "s=0\n",
    "for i in range(4):\n",
    "    Confusion[Ytest[i],ypred[i]]+=1\n",
    "    s+=(Ytest[i]==ypred[i])\n",
    "accuracy=s/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189bf15f-2a6d-40ac-902b-e83f40081ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c2554-3d83-45a7-b88e-f4cbe7203805",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43633ba-aeb2-4e0b-b6dc-356ac1867ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7536fce2-7e54-4fc3-8dde-f640284a057f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
